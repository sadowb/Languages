# Language Parser and Abstract Syntax Tree Generator

## Project Overview

This project implements a complete Lexer, Parser, and Abstract Syntax Tree (AST) Generator for a custom programming language. Developed as part of a formal language and compiler construction assignment, the core of the system is a parser that validates code against an updated and simplified grammar. It uses the AnyTree library for tree visualization.

The parser's logic was a significant and challenging undertaking, requiring a near-complete rewrite and several days of debugging and testing. The final system successfully parses tokens and produces both the Concrete Syntax Tree (CST) and the Abstract Syntax Tree (AST).

## Key Features

The following functionalities are implemented in the parser and abstract parser:

* Complete Parsing The parser can successfully process tokens generated by the lexer against the updated grammar.
* Concrete Syntax Tree (CST) The system generates and prints the full syntax tree to the terminal. It also exports a text file named concrete_tree.txt for an intuitive visualization.
* Abstract Syntax Tree (AST) The abstract parser generates the reduced tree in the terminal. The AST is saved to a file named abstract_tree. This was created by only leaving the children of the terminals and backtracking the nodes to their parent.
* Tree Reduction Customization The tree can be further reduced by changing the update_tree list. This allows you to include and add the nodes you want to keep, changing which terminals are reduced from the tree.
* Token Fidelity The ability to keep the values of the tokens was added so they can be inserted correctly into the tree.
* Robustness More exceptions for syntax errors were added to the code.

## Getting Started

### Prerequisites

You need to have the AnyTree library installed on your local machine to run the project.

pip install anytree

### How to Run

You can run the parser code or the abstract parser code first; either way, they are connected, and running one will call the other's components. The abstract parser will call the parser, and the parser will call the lexer to create the tokens.

Assuming the test source file is already in the machine, the parser will search for it.

# Run the parser 
python parser.py

# OR run the abstract parser
python abstract_parser.py

### Output

Upon execution, the program will update the file token and generate both the tree at the terminal and the following files:

* concrete_tree.txt: The full Concrete Syntax Tree.
* abstract_tree: The final Abstract Syntax Tree.

## Updated Grammar Specification

The grammar was simplified a lot and updated to complete the parser.

* Statements: The grammar was simplified by creating the statement with endline (<statement_w_endl>) and statement without end of line (<statement_wo_endl>).
* Function Calls: The usage of complex operations like ag.i(4,4) was removed and simplified to only ag(4,4) normal function calls.
* Operations: Changes were made to array handling and arithmetic operations to accept more operations.

**Key Grammar Rules (Non-Terminal :: Rule):**

* <language> :: <functions> <Main_body>
* <Main_body> :: BEGIN <Statements> END
* <statement> :: <statement> <statement> | <statement_w_endl> NEWL | <statement_wo_endl>| ε
* <functionRE> :: DEFINE ID <parse_functionCall> OPCURL <statements> CLCURL
* <arith_op> :: <check> ASSIGN <arith_expr>
* <loop> :: LOOP<condition>OPCURL <statements>CLCURL
* <if_statement> :: IF<condition>OPCURL<Statements>CLCURL<else_statement>

## Challenges and Future Work

* Parser Logic: The parser was the biggest challenge. I had to rewrite most of the code from scratch and fix the nodes to be at their right place in the tree. I worked on the parser logic for four days, fixing a lot of logical issues within the code.
* Missing Component (Part 5): I got stuck on Part 5 (the vim module) and did not complete it, as I didn’t know how to approach it.
* Static Semantics: I did not implement static semantics. This was primarily because we do not have global variables, and I couldn't find a way to keep track of whether variables were declared before use.
* Lexer File Dependency: There is still an issue where the file token needs to be present for the lexer to work.
